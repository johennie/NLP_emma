{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a05bcd-83db-4602-8a0b-7bbfdbc8e0ca",
   "metadata": {},
   "source": [
    "# emma_ch1_metrics\n",
    "Learning exercise inspired by *Natural Language Processing with Python* (Bird, Klein, Loper).  \n",
    "Uses NLTK's built-in Gutenberg corpus (`austen-emma.txt`) and computes simple per-sentence metrics for **Chapter I**.\n",
    "\n",
    "© 2025 Johennie Helton. Licensed under the [Apache License 2.0](http://www.apache.org/licenses/LICENSE-2.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a48a3fe0-9a65-4567-98d4-0fd38266dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import csv\n",
    "from statistics import mean\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk import word_tokenize, sent_tokenize, pos_tag\n",
    "\n",
    "# --- One-time downloads (uncomment on first run) ---\n",
    "#nltk.download('gutenberg')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4716015",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_chapter_1(raw_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Very simple extractor for the first chapter in Austen's Emma as distributed in NLTK.\n",
    "    Looks for 'CHAPTER I' and 'CHAPTER II' boundaries.\n",
    "    Falls back to a prefix if patterns aren't found (shouldn't happen for this file).\n",
    "    \"\"\"\n",
    "    # Try classic Roman numerals or digits just in case\n",
    "    pattern = r'CHAPTER\\s+[IVXLC\\d]+'\n",
    "    matches = list(re.finditer(pattern, raw_text))\n",
    "    if len(matches) >= 2:\n",
    "        start = matches[0].end()\n",
    "        end = matches[1].start()\n",
    "        return raw_text[start:end].strip()\n",
    "    # Fallback: take first ~6k characters after first CHAPTER occurrence\n",
    "    first = re.search(pattern, raw_text)\n",
    "    if first:\n",
    "        start = first.end()\n",
    "        return raw_text[start:start+6000].strip()\n",
    "    # Last resort: just take the beginning chunk\n",
    "    return raw_text[:6000].strip()\n",
    "\n",
    "def is_alpha_token(t: str) -> bool:\n",
    "    return re.fullmatch(r\"[A-Za-z’-]+\", t) is not None\n",
    "\n",
    "def syllables_en(word: str) -> int:\n",
    "    \"\"\"\n",
    "    Heuristic syllable counter (English). Good enough for an educational demo.\n",
    "    \"\"\"\n",
    "    w = re.sub(r\"[^a-z]\", \"\", word.lower())\n",
    "    if not w:\n",
    "        return 0\n",
    "    vowels = \"aeiouy\"\n",
    "    count = 0\n",
    "    prev_v = False\n",
    "    for ch in w:\n",
    "        is_v = ch in vowels\n",
    "        if is_v and not prev_v:\n",
    "            count += 1\n",
    "        prev_v = is_v\n",
    "    if w.endswith(\"e\") and count > 1:\n",
    "        count -= 1\n",
    "    return max(count, 1)\n",
    "\n",
    "def safe_div(n, d):\n",
    "    return n / d if d else 0.0\n",
    "\n",
    "def analyze_sentence(sent_text: str) -> dict:\n",
    "    tokens = word_tokenize(sent_text)\n",
    "    alpha = [t for t in tokens if is_alpha_token(t)]\n",
    "    lower = [t.lower() for t in alpha]\n",
    "\n",
    "    n_tokens = len(lower)\n",
    "    n_types = len(set(lower))\n",
    "    ttr = safe_div(n_types, n_tokens)\n",
    "    avg_word_len = safe_div(sum(len(w) for w in lower), n_tokens)\n",
    "\n",
    "    # POS tagging\n",
    "    tags = pos_tag(lower)\n",
    "\n",
    "    is_verb = lambda tag: tag.startswith(\"VB\")\n",
    "    is_adv  = lambda tag: tag.startswith(\"RB\")\n",
    "    is_adj  = lambda tag: tag.startswith(\"JJ\")\n",
    "    is_noun = lambda tag: tag.startswith(\"NN\")\n",
    "\n",
    "    n_verbs = sum(1 for _, t in tags if is_verb(t))\n",
    "    n_advs  = sum(1 for _, t in tags if is_adv(t))\n",
    "    n_adjs  = sum(1 for _, t in tags if is_adj(t))\n",
    "    n_nouns = sum(1 for _, t in tags if is_noun(t))\n",
    "\n",
    "    content_words = n_verbs + n_advs + n_adjs + n_nouns\n",
    "    lexical_density = safe_div(content_words, n_tokens)\n",
    "\n",
    "    # Syllables & a per-sentence Flesch-ish score (rough)\n",
    "    syll_count = sum(syllables_en(w) for w in lower)\n",
    "    flesch = 206.835 - 1.015 * n_tokens - 84.6 * safe_div(syll_count, n_tokens) if n_tokens else 0.0\n",
    "\n",
    "    return {\n",
    "        \"sentence_text\": sent_text.strip(),\n",
    "        \"n_tokens\": n_tokens,\n",
    "        \"n_types\": n_types,\n",
    "        \"ttr\": round(ttr, 3),\n",
    "        \"n_nouns\": n_nouns,\n",
    "        \"n_verbs\": n_verbs,\n",
    "        \"n_adjs\": n_adjs,\n",
    "        \"n_advs\": n_advs,\n",
    "        \"lexical_density\": round(lexical_density, 3),\n",
    "        \"avg_word_len\": round(avg_word_len, 2),\n",
    "        \"syllables\": syll_count,\n",
    "        \"flesch\": round(flesch, 1),\n",
    "        \"chars\": len(sent_text),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab1ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = gutenberg.raw('austen-emma.txt')\n",
    "ch1 = extract_chapter_1(raw)\n",
    "\n",
    "# Sentences (punkt)\n",
    "sentences = sent_tokenize(ch1)\n",
    "\n",
    "rows = []\n",
    "for idx, s in enumerate(sentences, 1):\n",
    "    m = analyze_sentence(s)\n",
    "    m[\"sent_index\"] = idx\n",
    "    rows.append(m)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db52362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_index</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>n_types</th>\n",
       "      <th>ttr</th>\n",
       "      <th>n_nouns</th>\n",
       "      <th>n_verbs</th>\n",
       "      <th>n_adjs</th>\n",
       "      <th>n_advs</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>syllables</th>\n",
       "      <th>flesch</th>\n",
       "      <th>chars</th>\n",
       "      <th>sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>34</td>\n",
       "      <td>0.850</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.575</td>\n",
       "      <td>4.83</td>\n",
       "      <td>60</td>\n",
       "      <td>39.3</td>\n",
       "      <td>239</td>\n",
       "      <td>Emma Woodhouse, handsome, clever, and rich, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>0.844</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.531</td>\n",
       "      <td>4.62</td>\n",
       "      <td>48</td>\n",
       "      <td>47.5</td>\n",
       "      <td>186</td>\n",
       "      <td>She was the youngest of the two daughters of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>0.805</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.585</td>\n",
       "      <td>4.39</td>\n",
       "      <td>59</td>\n",
       "      <td>43.5</td>\n",
       "      <td>223</td>\n",
       "      <td>Her mother\\nhad died too long ago for her to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>0.920</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>4.68</td>\n",
       "      <td>39</td>\n",
       "      <td>49.5</td>\n",
       "      <td>151</td>\n",
       "      <td>Sixteen years had Miss Taylor been in Mr. Wood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>4.50</td>\n",
       "      <td>13</td>\n",
       "      <td>61.2</td>\n",
       "      <td>51</td>\n",
       "      <td>Between _them_ it was more the intimacy\\nof si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_index  n_tokens  n_types    ttr  n_nouns  n_verbs  n_adjs  n_advs  \\\n",
       "0           1        40       34  0.850       10        6       5       2   \n",
       "1           2        32       27  0.844        8        3       4       2   \n",
       "2           3        41       33  0.805        8        8       5       3   \n",
       "3           4        25       23  0.920        7        2       4       2   \n",
       "4           5         8        8  1.000        2        1       0       1   \n",
       "\n",
       "   lexical_density  avg_word_len  syllables  flesch  chars  \\\n",
       "0            0.575          4.83         60    39.3    239   \n",
       "1            0.531          4.62         48    47.5    186   \n",
       "2            0.585          4.39         59    43.5    223   \n",
       "3            0.600          4.68         39    49.5    151   \n",
       "4            0.500          4.50         13    61.2     51   \n",
       "\n",
       "                                       sentence_text  \n",
       "0  Emma Woodhouse, handsome, clever, and rich, wi...  \n",
       "1  She was the youngest of the two daughters of a...  \n",
       "2  Her mother\\nhad died too long ago for her to h...  \n",
       "3  Sixteen years had Miss Taylor been in Mr. Wood...  \n",
       "4  Between _them_ it was more the intimacy\\nof si...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics = pd.DataFrame(rows, columns=[\n",
    "    \"sent_index\",\n",
    "    \"n_tokens\", \"n_types\", \"ttr\",\n",
    "    \"n_nouns\", \"n_verbs\", \"n_adjs\", \"n_advs\", \"lexical_density\",\n",
    "    \"avg_word_len\", \"syllables\", \"flesch\", \"chars\",\n",
    "    \"sentence_text\"\n",
    "])\n",
    "\n",
    "# Show the first few rows interactively\n",
    "df_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb2e1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Emma, Chapter I per-sentence metrics ===\n",
      "Sentences: 162\n",
      "Avg tokens per sentence: 20.36\n",
      "Avg lexical density:      0.570\n",
      "Avg Flesch score:         71.0\n"
     ]
    }
   ],
   "source": [
    "    # Print a tiny summary\n",
    "    print(\"=== Emma, Chapter I per-sentence metrics ===\")\n",
    "    print(f\"Sentences: {len(rows)}\")\n",
    "    print(f\"Avg tokens per sentence: {mean(r['n_tokens'] for r in rows):.2f}\")\n",
    "    print(f\"Avg lexical density:      {mean(r['lexical_density'] for r in rows):.3f}\")\n",
    "    print(f\"Avg Flesch score:         {mean(r['flesch'] for r in rows):.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff768fa-bed4-4f07-9458-7e5c8e738ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309a278-e4d2-4bc7-96af-af0027629b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
